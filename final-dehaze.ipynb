{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#for indoor\n\nimport numpy as np\nimport cv2\nimport os\nimport torch\nimport torch.utils.data as data\nfrom torchvision import transforms\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom skimage.metrics import structural_similarity as ssim\n\n# Data Loading and Processing\nclass DehazingDataset(data.Dataset):\n    def init(self, hazy_images_path, clean_images_path, transform=None):\n        self.hazy_images = sorted([os.path.join(hazy_images_path, f)\n                                   for f in os.listdir(hazy_images_path)\n                                   if f.endswith(('.jpg', '.jpeg', '.png'))])\n        self.clean_images = sorted([os.path.join(clean_images_path, f)\n                                    for f in os.listdir(clean_images_path)\n                                    if f.endswith(('.jpg', '.jpeg', '.png'))])\n        self.size = min(len(self.hazy_images), len(self.clean_images))\n        self.hazy_images = self.hazy_images[:self.size]\n        self.clean_images = self.clean_images[:self.size]\n        self.filter_files()\n        self.size = len(self.hazy_images)\n        self.transform = transform\n\n    def filter_files(self):\n        hazy_ims = []\n        clean_ims = []\n        for hazy_img_path, clean_img_path in zip(self.hazy_images, self.clean_images):\n            hazy = Image.open(hazy_img_path)\n            clean = Image.open(clean_img_path)\n            if hazy.size == clean.size:\n                hazy_ims.append(hazy_img_path)\n                clean_ims.append(clean_img_path)\n        self.hazy_images = hazy_ims\n        self.clean_images = clean_ims\n\n    def getitem(self, index):\n        hazy_img = self.rgb_loader(self.hazy_images[index])\n        clean_img = self.rgb_loader(self.clean_images[index])\n        if self.transform:\n            hazy_img = self.transform(hazy_img)\n            clean_img = self.transform(clean_img)\n        return hazy_img, clean_img\n\n    def rgb_loader(self, path):\n        with open(path, 'rb') as f:\n            img = Image.open(f)\n            return img.convert('RGB')\n\n    def len(self):\n        return self.size\n\n    def show_grayscale_image(self, tensor_image):\n        np_image = tensor_image.squeeze(0).numpy()\n        np_image = np.clip(np_image, 0, 1)\n        plt.imshow(np_image, cmap='gray')\n        plt.axis('off')\n        plt.show()\n\n# Dehazing Model\ndef adjust_brightness_contrast(image, brightness=0, contrast=21):\n    \"\"\"Adjust the brightness and contrast of an image.\"\"\"\n    brightness = int((brightness - 0) * 255 / 100)  # Convert brightness to scale\n    contrast = int((contrast - 0) * 127 / 100)  # Convert contrast to scale\n    return cv2.convertScaleAbs(image, alpha=1 + contrast / 127.0, beta=brightness)\n\ndef resize_image(image, size):\n    return cv2.resize(image, size, interpolation=cv2.INTER_LINEAR)\n\ndef extract_features(image):\n    hsv_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n    brightness = hsv_image[:, :, 2]\n    saturation = hsv_image[:, :, 1]\n\n    mean_brightness = np.mean(brightness)\n    mean_saturation = np.mean(saturation)\n\n    brightness_sum = mean_brightness + mean_saturation\n    if brightness_sum == 0:\n        brightness_sum = 1e-11\n\n    eta = mean_brightness / brightness_sum\n    chi = mean_saturation / brightness_sum\n\n    return eta, chi\n\ndef calculate_beta(eta, chi, c1, c2, c3):\n    epsilon = np.random.normal(0, 0.01)  # Small noise\n    return c1 + c2 * eta + c3 * chi + epsilon\n\ndef refined_transmission_map(depth_map, beta):\n    tr_map = np.exp(-beta * depth_map)\n    return tr_map\n\ndef improved_dehaze_image(image, depth_map, c1, c2, c3, gamma=1.0, brightness=2, contrast=5):\n    eta, chi = extract_features(image)\n    beta = calculate_beta(eta, chi, c1, c2, c3)\n    tr_map = refined_transmission_map(depth_map, beta)\n\n    restored_image = image / (tr_map + 1e-5)\n    restored_image = np.clip(restored_image, 0, 1)\n    # Adjust brightness and contrast\n    restored_image_uint8 = (restored_image * 255).astype(np.uint8)\n    restored_image_adjusted = adjust_brightness_contrast(restored_image_uint8, brightness, contrast)\n    gamma_corrected_image = np.power(restored_image_adjusted / 255.0, 1 / gamma)\n\n    return gamma_corrected_image\n\ndef load_dataset(clear_folder, hazy_folder, size=(256, 256), max_images=200):\n    clear_images = []\n    hazy_images = []\n\n    clear_files = sorted(os.listdir(clear_folder))[:max_images]\n    hazy_files = sorted(os.listdir(hazy_folder))[:max_images]\n\n    if not clear_files or not hazy_files:\n        raise ValueError(\"One or both folders are empty or contain no valid image files.\")\n\n    for img_name in clear_files:\n        img_path = os.path.join(clear_folder, img_name)\n        clear_img = cv2.imread(img_path)\n        if clear_img is None:\n            continue\n        clear_img = cv2.cvtColor(clear_img, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n        clear_img = resize_image(clear_img, size)\n        clear_images.append(clear_img)\n\n    for img_name in hazy_files:\n        img_path = os.path.join(hazy_folder, img_name)\n        hazy_img = cv2.imread(img_path)\n        if hazy_img is None:\n            continue\n        hazy_img = cv2.cvtColor(hazy_img, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n        hazy_img = resize_image(hazy_img, size)\n        hazy_images.append(hazy_img)\n\n    min_length = min(len(clear_images), len(hazy_images))\n    clear_images = clear_images[:min_length]\n    hazy_images = hazy_images[:min_length]\n\n    return np.array(clear_images), np.array(hazy_images)\n\n# Function to display images side by side\ndef display_images_side_by_side(images, titles=None):\n    \"\"\"Display a list of images side by side.\"\"\"\n    fig, axes = plt.subplots(1, len(images), figsize=(15, 5))\n    for i, image in enumerate(images):\n        axes[i].imshow(image)\n        axes[i].axis('off')\n        if titles:\n            axes[i].set_title(titles[i])\n    plt.show()\n\ndef main(clear_folder, hazy_folder, output_folder):\n    clear_images, hazy_images = load_dataset(clear_folder, hazy_folder)\n\n    if len(clear_images) == 0 or len(hazy_images) == 0:\n        raise ValueError(\"Image arrays are empty. Please check your image paths.\")\n\n    train_clear, test_clear, train_hazy, test_hazy = train_test_split(\n        clear_images, hazy_images, test_size=0.1, random_state=42)\n\n    train_features = []\n    train_beta_values = []\n   \n    # Training the regression model\n    for clear_img, hazy_img in zip(train_clear, train_hazy):\n        eta, chi = extract_features(clear_img)\n        depth_map = np.abs(clear_img - hazy_img)\n        ratio = hazy_img / (clear_img + 1e-5)\n        beta = -np.log(np.mean(ratio)) / np.mean(depth_map)\n        train_features.append([eta, chi])\n        train_beta_values.append(beta)\n\n    train_features = np.array(train_features)\n    train_beta_values = np.array(train_beta_values)\n    train_features = train_features.reshape(-1, 2)\n\n    regressor = LinearRegression()\n    regressor.fit(train_features, train_beta_values)\n\n    c1, c2, c3 = regressor.intercept_, regressor.coef_[0], regressor.coef_[1]\n\n    if not os.path.exists(output_folder):\n        os.makedirs(output_folder)\n\n    total_ssim = 0\n    num_images = len(test_clear)\n\n    for i, (test_clear_img, test_hazy_img) in enumerate(zip(test_clear, test_hazy)):\n        depth_map = np.abs(test_clear_img - test_hazy_img)\n        restored_img = improved_dehaze_image(test_hazy_img, depth_map, c1, c2, c3, gamma=1.0, brightness=10, contrast=1)\n\n        restored_img_uint8 = (restored_img * 255).astype(np.uint8)\n        cv2.imwrite(os.path.join(output_folder, f'restored_image_{i}.png'), cv2.cvtColor(restored_img_uint8, cv2.COLOR_RGB2BGR))\n\n        # Ensure that the SSIM window size is compatible with your image size\n        ssim_value = ssim(test_clear_img, restored_img, win_size=25, channel_axis=-1, data_range=41.0)\n        total_ssim += ssim_value\n        display_images_side_by_side([test_hazy_img, restored_img, test_clear_img], titles=[\"Hazy Image\", \"Dehazed Image\", \"Clear Image\"])\n\n    print(\"Mean SSIM value:\", total_ssim / num_images)\n\n# Integration\nif __name__ == \"__main__\":\n    clear_folder = '/kaggle/input/i-haze/I-HAZE/val/clear'\n    hazy_folder = '/kaggle/input/i-haze/I-HAZE/val/hazy'\n    output_folder = '/kaggle/working/'\n\n    # Run the dehazing model\n    main(clear_folder, hazy_folder, output_folder)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}